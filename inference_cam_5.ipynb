{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AD 2-Stage Inference + CAM Visualization\n",
    "\n",
    "**Stage 1**: CN vs CI (MCI+AD) — `cn_f189.pth` (MCIClassifierWithAttention)\n",
    "\n",
    "**Stage 2**: MCI vs AD — `ci_f184.pth` (MCIClassifier3D)\n",
    "\n",
    "전체 데이터(7.data_mci,ad)를 분석하고, **MCI 정답을 맞춘 이미지**에 대해 ROI / Grad-CAM / Pixel-Gradient / PCG-CAM 시각화를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"/Users/machanho/Desktop/uv/ad\")\n",
    "\n",
    "CN_MODEL_PATH = BASE_DIR / \"1.pth\"   # Stage 1: CN vs CI\n",
    "CI_MODEL_PATH = BASE_DIR / \"test.pth\"   # Stage 2: MCI vs AD\n",
    "DATA_DIR = BASE_DIR / \"7.data_mci,ad\"\n",
    "METADATA_PATH = BASE_DIR / \"idaSearch_image_download_metadata_2510.csv\"\n",
    "OUTPUT_DIR = BASE_DIR / \"inference_output5\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TARGET_SHAPE = (96, 112, 96)\n",
    "NUM_CLASSES = 2\n",
    "DROPOUT = 0.25\n",
    "\n",
    "# CAM 시각화할 MCI 정답 샘플 최대 개수\n",
    "MAX_CAM_SAMPLES = 5\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ROI 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI_DEFINITIONS = {\n",
    "    # A. 내측 측두엽 (MTL)\n",
    "    \"hippocampus_L\":      {\"center\": [48, 54, 36], \"sigma\": 4.0,  \"weight\": 2.0, \"description\": \"좌측 해마 - MCI/AD 핵심\"},\n",
    "    \"hippocampus_R\":      {\"center\": [48, 54, 60], \"sigma\": 4.0,  \"weight\": 2.0, \"description\": \"우측 해마\"},\n",
    "    \"entorhinal_L\":       {\"center\": [54, 48, 34], \"sigma\": 3.5,  \"weight\": 2.0, \"description\": \"좌측 엔토라이날 - MCI 초기\"},\n",
    "    \"entorhinal_R\":       {\"center\": [54, 48, 62], \"sigma\": 3.5,  \"weight\": 2.0, \"description\": \"우측 엔토라이날\"},\n",
    "    \"parahippocampal_L\":  {\"center\": [48, 42, 32], \"sigma\": 4.0,  \"weight\": 1.6, \"description\": \"좌측 해마방회\"},\n",
    "    \"parahippocampal_R\":  {\"center\": [48, 42, 64], \"sigma\": 4.0,  \"weight\": 1.6, \"description\": \"우측 해마방회\"},\n",
    "    \"amygdala_L\":         {\"center\": [42, 60, 34], \"sigma\": 3.5,  \"weight\": 1.5, \"description\": \"좌측 편도체\"},\n",
    "    \"amygdala_R\":         {\"center\": [42, 60, 62], \"sigma\": 3.5,  \"weight\": 1.5, \"description\": \"우측 편도체\"},\n",
    "    # B. AD signature + 연관 피질 영역\n",
    "    \"posterior_cingulate\": {\"center\": [30, 35, 48], \"sigma\": 5.0,  \"weight\": 1.4, \"description\": \"후대상피질 - AD 확장 패턴\"},\n",
    "    \"precuneus\":          {\"center\": [65, 30, 48], \"sigma\": 6.0,  \"weight\": 1.4, \"description\": \"precuneus - AD 확장 패턴\"},\n",
    "    \"inferior_temporal_L\": {\"center\": [42, 60, 22], \"sigma\": 8.0, \"weight\": 1.3, \"description\": \"좌측 하측두회\"},\n",
    "    \"inferior_temporal_R\": {\"center\": [42, 60, 72], \"sigma\": 8.0, \"weight\": 1.3, \"description\": \"우측 하측두회\"},\n",
    "    \"middle_temporal_L\":  {\"center\": [48, 52, 24], \"sigma\": 8.0,  \"weight\": 1.3, \"description\": \"좌측 중측두회\"},\n",
    "    \"middle_temporal_R\":  {\"center\": [48, 52, 72], \"sigma\": 8.0,  \"weight\": 1.3, \"description\": \"우측 중측두회\"},\n",
    "    \"fusiform_L\":         {\"center\": [38, 58, 28], \"sigma\": 6.0,  \"weight\": 1.3, \"description\": \"좌측 방추상회\"},\n",
    "    \"fusiform_R\":         {\"center\": [38, 58, 68], \"sigma\": 6.0,  \"weight\": 1.3, \"description\": \"우측 방추상회\"},\n",
    "    \"parietal_L\":         {\"center\": [68, 45, 26], \"sigma\": 8.0,  \"weight\": 1.2, \"description\": \"좌측 두정엽\"},\n",
    "    \"parietal_R\":         {\"center\": [68, 45, 70], \"sigma\": 8.0,  \"weight\": 1.2, \"description\": \"우측 두정엽\"},\n",
    "    \"frontal\":            {\"center\": [55, 85, 48], \"sigma\": 10.0, \"weight\": 1.1, \"description\": \"전두엽 - 후기 확장\"},\n",
    "    # C. 뇌실 (Ventricles)\n",
    "    \"lateral_ventricle\":  {\"center\": [35, 56, 48], \"sigma\": 12.0, \"weight\": 1.5, \"description\": \"측뇌실 - 위축 보상 확장\"},\n",
    "    \"inferior_horn_L\":    {\"center\": [35, 56, 30], \"sigma\": 8.0,  \"weight\": 1.5, \"description\": \"좌측 하각 - 해마 위축 지표\"},\n",
    "    \"inferior_horn_R\":    {\"center\": [35, 56, 66], \"sigma\": 8.0,  \"weight\": 1.5, \"description\": \"우측 하각\"},\n",
    "}\n",
    "\n",
    "BASE_WEIGHT = 1.0\n",
    "\n",
    "print(f\"ROI 수: {len(ROI_DEFINITIONS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ROI Spatial Attention\n",
    "# ============================================================\n",
    "\n",
    "def create_roi_weight_map(\n",
    "    target_shape: tuple[int, int, int],\n",
    "    roi_definitions: dict,\n",
    "    base_weight: float = BASE_WEIGHT\n",
    ") -> torch.Tensor:\n",
    "    D, H, W = target_shape\n",
    "    weight_map = torch.ones(1, 1, D, H, W) * base_weight\n",
    "    d = torch.arange(D).float()\n",
    "    h = torch.arange(H).float()\n",
    "    w = torch.arange(W).float()\n",
    "    dd, hh, ww = torch.meshgrid(d, h, w, indexing='ij')\n",
    "    for name, roi in roi_definitions.items():\n",
    "        center = roi[\"center\"]\n",
    "        sigma = roi[\"sigma\"]\n",
    "        roi_weight = roi[\"weight\"]\n",
    "        dist_sq = ((dd - center[0])**2 + (hh - center[1])**2 + (ww - center[2])**2)\n",
    "        gaussian = torch.exp(-dist_sq / (2 * sigma**2))\n",
    "        weight_map[0, 0] += gaussian * max(0.0, roi_weight - base_weight)\n",
    "    return weight_map\n",
    "\n",
    "\n",
    "class ROISpatialAttention(nn.Module):\n",
    "    def __init__(self, target_shape, roi_definitions, base_weight=1.0):\n",
    "        super().__init__()\n",
    "        weight_map = create_roi_weight_map(target_shape, roi_definitions, base_weight)\n",
    "        self.register_buffer('weight_map', weight_map)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return x * self.weight_map\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Building Blocks\n",
    "# ============================================================\n",
    "\n",
    "class ConvBlock3D(nn.Module):\n",
    "    def __init__(self, in_ch: int, out_ch: int) -> None:\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv3d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv3d(out_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool3d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, channels: int, reduction: int = 8) -> None:\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channels // reduction, channels, bias=False),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        b, c, _, _, _ = x.shape\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Stage 1 Model: MCIClassifierWithAttention (CN vs CI)\n",
    "# ============================================================\n",
    "\n",
    "class MCIClassifierWithAttention(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout=DROPOUT, roi_attention=None):\n",
    "        super().__init__()\n",
    "        self.roi_attention = roi_attention\n",
    "        self.block1 = ConvBlock3D(1, 32)\n",
    "        self.block2 = ConvBlock3D(32, 64)\n",
    "        self.block3 = ConvBlock3D(64, 128)\n",
    "        self.block4 = ConvBlock3D(128, 256)\n",
    "        self.attn = ChannelAttention(256)\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.roi_attention is not None:\n",
    "            x = self.roi_attention(x)\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.attn(x)\n",
    "        x = self.pool(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Stage 2 Model: MCIClassifier3D (MCI vs AD)\n",
    "# ============================================================\n",
    "\n",
    "class MCIClassifier3D(nn.Module):\n",
    "    def __init__(self, num_classes=2, dropout=DROPOUT, roi_attention=None):\n",
    "        super().__init__()\n",
    "        self.roi_attention = roi_attention\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvBlock3D(1, 32),\n",
    "            ConvBlock3D(32, 64),\n",
    "            ConvBlock3D(64, 128),\n",
    "            ConvBlock3D(128, 256),\n",
    "        )\n",
    "        self.pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.roi_attention is not None:\n",
    "            x = self.roi_attention(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.pool(x)\n",
    "        return self.classifier(x)\n",
    "\n",
    "\n",
    "print(\"모델 정의 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROI Attention 모듈 생성\n",
    "roi_attention_cn = ROISpatialAttention(TARGET_SHAPE, ROI_DEFINITIONS, BASE_WEIGHT)\n",
    "roi_attention_ci = ROISpatialAttention(TARGET_SHAPE, ROI_DEFINITIONS, BASE_WEIGHT)\n",
    "\n",
    "# PyTorch 2.6 weights_only 안전 로드 설정 (trusted models)\n",
    "import numpy as np\n",
    "from torch.serialization import add_safe_globals\n",
    "add_safe_globals([np.core.multiarray._reconstruct, np.ndarray, np.dtype])\n",
    "\n",
    "\n",
    "def _load_checkpoint_state_dict(path, map_location):\n",
    "    ckpt = torch.load(path, map_location=map_location, weights_only=False)\n",
    "    if isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "        state_dict = ckpt[\"state_dict\"]\n",
    "    else:\n",
    "        state_dict = ckpt\n",
    "    # DataParallel prefix 제거\n",
    "    if isinstance(state_dict, dict) and any(k.startswith(\"module.\") for k in state_dict.keys()):\n",
    "        state_dict = {k.replace(\"module.\", \"\", 1): v for k, v in state_dict.items()}\n",
    "    return state_dict\n",
    "\n",
    "\n",
    "def _infer_model_type(state_dict):\n",
    "    keys = list(state_dict.keys())\n",
    "    if any(k.startswith(\"encoder.\") for k in keys):\n",
    "        return \"encoder\"\n",
    "    if any(k.startswith(\"block1.\") for k in keys):\n",
    "        return \"block\"\n",
    "    return \"unknown\"\n",
    "\n",
    "\n",
    "def _build_model_for_state_dict(state_dict, roi_attention):\n",
    "    mtype = _infer_model_type(state_dict)\n",
    "    if mtype == \"encoder\":\n",
    "        return MCIClassifier3D(num_classes=NUM_CLASSES, dropout=DROPOUT, roi_attention=roi_attention)\n",
    "    # block* + attn 구조는 MCIClassifierWithAttention\n",
    "    return MCIClassifierWithAttention(num_classes=NUM_CLASSES, dropout=DROPOUT, roi_attention=roi_attention)\n",
    "\n",
    "\n",
    "def _load_model_from_checkpoint(path, roi_attention, stage_name):\n",
    "    state_dict = _load_checkpoint_state_dict(path, DEVICE)\n",
    "    model = _build_model_for_state_dict(state_dict, roi_attention)\n",
    "    missing, unexpected = model.load_state_dict(state_dict, strict=False)\n",
    "    if len(missing) or len(unexpected):\n",
    "        print(f\"[{stage_name}] state_dict 경고:\")\n",
    "        if missing:\n",
    "            print(f\"  Missing keys: {len(missing)}\")\n",
    "        if unexpected:\n",
    "            print(f\"  Unexpected keys: {len(unexpected)}\")\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Stage 1: CN vs CI\n",
    "cn_model = _load_model_from_checkpoint(CN_MODEL_PATH, roi_attention_cn, \"Stage 1 (CN vs CI)\")\n",
    "print(f\"Stage 1 (CN vs CI) 모델 로드 완료: {CN_MODEL_PATH.name}\")\n",
    "print(f\"  파라미터 수: {sum(p.numel() for p in cn_model.parameters()):,}\")\n",
    "\n",
    "# Stage 2: MCI vs AD\n",
    "ci_model = _load_model_from_checkpoint(CI_MODEL_PATH, roi_attention_ci, \"Stage 2 (MCI vs AD)\")\n",
    "print(f\"Stage 2 (MCI vs AD) 모델 로드 완료: {CI_MODEL_PATH.name}\")\n",
    "print(f\"  파라미터 수: {sum(p.numel() for p in ci_model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전체 데이터 인덱싱 + NIfTI 로드 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_SUBJECT_RE = re.compile(r\"__([0-9]{3}_S_[0-9]+)__\")\n",
    "_SUBJECT_FALLBACK_RE = re.compile(r\"([0-9]{3}_S_[0-9]+)\")\n",
    "\n",
    "\n",
    "def _extract_subject_id(name: str) -> str | None:\n",
    "    match = _SUBJECT_RE.search(name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    match = _SUBJECT_FALLBACK_RE.search(name)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_nifti(path, target_shape=TARGET_SHAPE):\n",
    "    \"\"\"NIfTI -> (1, 1, D, H, W) 텐서\"\"\"\n",
    "    img = nib.load(str(path))\n",
    "    data = img.get_fdata()\n",
    "    if data.ndim == 4:\n",
    "        data = data[..., 0]\n",
    "    v = data.astype(np.float32)\n",
    "    lo, hi = np.percentile(v, (1, 99))\n",
    "    if hi <= lo:\n",
    "        lo, hi = v.min(), v.max()\n",
    "    if hi > lo:\n",
    "        v = np.clip((v - lo) / (hi - lo), 0, 1).astype(np.float32)\n",
    "    else:\n",
    "        v = np.zeros_like(v, dtype=np.float32)\n",
    "    vol = torch.from_numpy(v).unsqueeze(0).unsqueeze(0)\n",
    "    vol = F.interpolate(vol, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "    return vol\n",
    "\n",
    "\n",
    "# 메타데이터 로드\n",
    "meta = pd.read_csv(METADATA_PATH)\n",
    "meta = meta[[\"Subject ID\", \"Research Group\"]].dropna()\n",
    "meta = meta.drop_duplicates(subset=[\"Subject ID\"], keep=\"last\")\n",
    "\n",
    "# 전체 파일 인덱싱\n",
    "rows = []\n",
    "for path in sorted(DATA_DIR.glob(\"*.nii*\")):\n",
    "    subject_id = _extract_subject_id(path.name)\n",
    "    if not subject_id:\n",
    "        continue\n",
    "    row = meta.loc[meta[\"Subject ID\"] == subject_id]\n",
    "    if row.empty:\n",
    "        continue\n",
    "    group = row.iloc[0][\"Research Group\"]\n",
    "    if group not in (\"CN\", \"MCI\", \"AD\"):\n",
    "        continue\n",
    "    rows.append({\"path\": str(path), \"subject_id\": subject_id, \"group\": group, \"filename\": path.name})\n",
    "\n",
    "df_all = pd.DataFrame(rows)\n",
    "\n",
    "print(f\"전체 파일 수: {len(df_all)}\")\n",
    "print(f\"\\n그룹별 분포:\")\n",
    "print(df_all[\"group\"].value_counts().to_string())\n",
    "print(f\"\\n고유 Subject 수: {df_all['subject_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전체 데이터 2-Stage 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CN_CLASS_NAMES = [\"CN\", \"CI\"]\n",
    "CI_CLASS_NAMES = [\"MCI\", \"AD\"]\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in tqdm(df_all.iterrows(), total=len(df_all), desc=\"Inference\"):\n",
    "    try:\n",
    "        vol = load_nifti(row[\"path\"])\n",
    "        vol_dev = vol.to(DEVICE)\n",
    "    except Exception as e:\n",
    "        print(f\"  SKIP {row['filename']}: {e}\")\n",
    "        continue\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Stage 1: CN vs CI\n",
    "        logits1 = cn_model(vol_dev)\n",
    "        probs1 = torch.softmax(logits1, dim=1)\n",
    "        pred1 = int(torch.argmax(logits1, dim=1)[0])\n",
    "        prob_cn = probs1[0, 0].item()\n",
    "        prob_ci = probs1[0, 1].item()\n",
    "\n",
    "        # Stage 2: MCI vs AD (항상 실행하여 기록)\n",
    "        logits2 = ci_model(vol_dev)\n",
    "        probs2 = torch.softmax(logits2, dim=1)\n",
    "        pred2 = int(torch.argmax(logits2, dim=1)[0])\n",
    "        prob_mci = probs2[0, 0].item()\n",
    "        prob_ad = probs2[0, 1].item()\n",
    "\n",
    "    # 최종 판정\n",
    "    if pred1 == 0:\n",
    "        final = \"CN\"\n",
    "    else:\n",
    "        final = CI_CLASS_NAMES[pred2]\n",
    "\n",
    "    results.append({\n",
    "        \"filename\": row[\"filename\"],\n",
    "        \"path\": row[\"path\"],\n",
    "        \"subject_id\": row[\"subject_id\"],\n",
    "        \"true_group\": row[\"group\"],\n",
    "        \"s1_pred\": CN_CLASS_NAMES[pred1],\n",
    "        \"s1_prob_cn\": prob_cn,\n",
    "        \"s1_prob_ci\": prob_ci,\n",
    "        \"s2_pred\": CI_CLASS_NAMES[pred2],\n",
    "        \"s2_prob_mci\": prob_mci,\n",
    "        \"s2_prob_ad\": prob_ad,\n",
    "        \"final_pred\": final,\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(OUTPUT_DIR / \"all_predictions.csv\", index=False)\n",
    "print(f\"\\n추론 완료: {len(df_results)}건 저장 -> {OUTPUT_DIR / 'all_predictions.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 전체 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"전체 추론 결과 요약\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Confusion Matrix\n",
    "ct = pd.crosstab(df_results[\"true_group\"], df_results[\"final_pred\"], margins=True)\n",
    "print(\"\\n[Confusion Matrix] True Group vs Final Prediction\")\n",
    "print(ct.to_string())\n",
    "\n",
    "# 그룹별 정확도\n",
    "print(\"\\n[그룹별 정확도]\")\n",
    "for grp in [\"CN\", \"MCI\", \"AD\"]:\n",
    "    sub = df_results[df_results[\"true_group\"] == grp]\n",
    "    if len(sub) == 0:\n",
    "        continue\n",
    "    correct = (sub[\"final_pred\"] == grp).sum()\n",
    "    print(f\"  {grp}: {correct}/{len(sub)} ({correct/len(sub)*100:.1f}%)\")\n",
    "\n",
    "total_correct = (df_results[\"final_pred\"] == df_results[\"true_group\"]).sum()\n",
    "print(f\"\\n  전체 정확도: {total_correct}/{len(df_results)} ({total_correct/len(df_results)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## MCI 정답 맞춘 샘플 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCI 정답: true_group == \"MCI\" AND final_pred == \"MCI\"\n",
    "df_mci_correct = df_results[\n",
    "    (df_results[\"true_group\"] == \"MCI\") & (df_results[\"final_pred\"] == \"MCI\")\n",
    "].copy()\n",
    "\n",
    "# MCI 확률이 높은 순으로 정렬\n",
    "df_mci_correct = df_mci_correct.sort_values(\"s2_prob_mci\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(f\"MCI 정답 맞춘 샘플 수: {len(df_mci_correct)}\")\n",
    "print(f\"MCI 전체 샘플 수: {(df_results['true_group'] == 'MCI').sum()}\")\n",
    "print(f\"MCI 정답률: {len(df_mci_correct) / max((df_results['true_group'] == 'MCI').sum(), 1) * 100:.1f}%\")\n",
    "\n",
    "print(f\"\\nCAM 분석 대상 (MCI prob 상위 {MAX_CAM_SAMPLES}개):\")\n",
    "cam_targets = df_mci_correct.head(MAX_CAM_SAMPLES)\n",
    "for i, row in cam_targets.iterrows():\n",
    "    print(f\"  {row['subject_id']} | S1(CI): {row['s1_prob_ci']*100:.1f}% | S2(MCI): {row['s2_prob_mci']*100:.1f}% | {row['filename']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## CAM 유틸리티"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _resolve_target_layer(model, prefer_attn: bool = False):\n",
    "    if prefer_attn and hasattr(model, \"attn\"):\n",
    "        return model.attn\n",
    "    if hasattr(model, \"encoder\"):\n",
    "        return model.encoder[-1].block[3]\n",
    "    if hasattr(model, \"block4\") and hasattr(model.block4, \"block\"):\n",
    "        return model.block4.block[3]\n",
    "    last_conv = None\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Conv3d):\n",
    "            last_conv = m\n",
    "    if last_conv is None:\n",
    "        raise RuntimeError(\"Grad-CAM target layer not found\")\n",
    "    return last_conv\n",
    "\n",
    "\n",
    "class GradCAM3D:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.activations = None\n",
    "        self.gradients = None\n",
    "        self._handles = []\n",
    "        self._handles.append(target_layer.register_forward_hook(\n",
    "            lambda _, __, out: setattr(self, 'activations', out)))\n",
    "        self._handles.append(target_layer.register_full_backward_hook(\n",
    "            lambda _, __, grad_out: setattr(self, 'gradients', grad_out[0])))\n",
    "\n",
    "    def remove(self):\n",
    "        for h in self._handles:\n",
    "            h.remove()\n",
    "        self._handles = []\n",
    "\n",
    "    def __call__(self, x, class_idx=None):\n",
    "        self.model.zero_grad(set_to_none=True)\n",
    "        logits = self.model(x)\n",
    "        if class_idx is None:\n",
    "            class_idx = int(torch.argmax(logits, dim=1)[0])\n",
    "        logits[:, class_idx].sum().backward()\n",
    "        weights = self.gradients.mean(dim=(2, 3, 4), keepdim=True)\n",
    "        cam = torch.relu((weights * self.activations).sum(dim=1, keepdim=True))\n",
    "        cam = cam - cam.min()\n",
    "        cam = cam / (cam.max() + 1e-6)\n",
    "        return cam\n",
    "\n",
    "\n",
    "def compute_roi_abnormality(activation_map, roi_definitions):\n",
    "    D, H, W = activation_map.shape\n",
    "    dd, hh, ww = np.meshgrid(\n",
    "        np.arange(D, dtype=np.float32),\n",
    "        np.arange(H, dtype=np.float32),\n",
    "        np.arange(W, dtype=np.float32),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    results = []\n",
    "    for name, roi in roi_definitions.items():\n",
    "        c = roi[\"center\"]\n",
    "        s = float(roi[\"sigma\"])\n",
    "        mask = np.exp(-((dd-c[0])**2 + (hh-c[1])**2 + (ww-c[2])**2) / (2*s**2))\n",
    "        score = float((activation_map * mask).sum() / (mask.sum() + 1e-6))\n",
    "        results.append({\"name\": name, \"description\": roi.get(\"description\", \"\"), \"score\": score})\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CAM ROI 제한 (해마만 보기)\n",
    "# ============================================================\n",
    "\n",
    "CAM_ONLY_HIPPOCAMPUS = True\n",
    "CAM_ROI_KEYS = (\"hippocampus_L\", \"hippocampus_R\")\n",
    "\n",
    "\n",
    "def create_roi_mask(target_shape, roi_definitions, keys=None, threshold=0.5):\n",
    "    D, H, W = target_shape\n",
    "    dd, hh, ww = np.meshgrid(\n",
    "        np.arange(D, dtype=np.float32),\n",
    "        np.arange(H, dtype=np.float32),\n",
    "        np.arange(W, dtype=np.float32),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    mask = np.zeros((D, H, W), dtype=np.float32)\n",
    "    for name, roi in roi_definitions.items():\n",
    "        if keys is not None and name not in keys:\n",
    "            continue\n",
    "        c = roi[\"center\"]\n",
    "        s = float(roi[\"sigma\"])\n",
    "        gaussian = np.exp(-((dd - c[0])**2 + (hh - c[1])**2 + (ww - c[2])**2) / (2 * s**2))\n",
    "        mask = np.maximum(mask, gaussian)\n",
    "    return (mask > threshold).astype(np.float32)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 뇌 마스크 생성\n",
    "# ============================================================\n",
    "\n",
    "def create_brain_mask(vol_np, threshold=0.05):\n",
    "    \"\"\"뇌 영역 마스크 생성 (배경 제거)\"\"\"\n",
    "    return (vol_np > threshold).astype(np.float32)\n",
    "\n",
    "\n",
    "def _get_slice(vol_np, brain_mask, dim, sl_idx):\n",
    "    \"\"\"vol_np 슬라이스를 brain_mask로 배경 제거하여 반환. (base, bm_2d) 튜플 반환.\"\"\"\n",
    "    if dim == 0:\n",
    "        base = vol_np[sl_idx, :, :]\n",
    "        bm = brain_mask[sl_idx, :, :] if brain_mask is not None else None\n",
    "    elif dim == 1:\n",
    "        base = vol_np[:, sl_idx, :]\n",
    "        bm = brain_mask[:, sl_idx, :] if brain_mask is not None else None\n",
    "    else:\n",
    "        base = vol_np[:, :, sl_idx]\n",
    "        bm = brain_mask[:, :, sl_idx] if brain_mask is not None else None\n",
    "    if bm is not None:\n",
    "        base = base * bm\n",
    "    return base, bm\n",
    "\n",
    "\n",
    "def _mask_heat(heat, thresh, bm_2d):\n",
    "    \"\"\"CAM heat를 threshold + brain_mask 둘 다 적용하여 마스킹.\"\"\"\n",
    "    if bm_2d is not None:\n",
    "        return np.ma.masked_where((heat < thresh) | (bm_2d == 0), heat)\n",
    "    return np.ma.masked_where(heat < thresh, heat)\n",
    "\n",
    "\n",
    "def percentile_in_mask(cam_np, mask_np=None, q: float = 95, fallback: float = 0.0) -> float:\n",
    "    \"\"\"mask 내부의 양수 값만으로 percentile 계산 (빈 경우 fallback).\"\"\"\n",
    "    if mask_np is None:\n",
    "        vals = cam_np[cam_np > 0]\n",
    "    else:\n",
    "        vals = (cam_np * mask_np)[mask_np > 0]\n",
    "        vals = vals[vals > 0]\n",
    "    if getattr(vals, \"size\", 0) == 0:\n",
    "        return float(fallback)\n",
    "    return float(np.percentile(vals, q))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 뇌 내부 상위 N개 활성화 클러스터 시각화\n",
    "# ============================================================\n",
    "\n",
    "def visualize_top_clusters(vol_np, cam_data, cam_name, brain_mask,\n",
    "                           stage_name, subject_id, output_dir,\n",
    "                           top_n=3, suppression_radius=10):\n",
    "    \"\"\"뇌 마스크 적용 후 NMS로 상위 N개 활성화 피크를 찾아 각각 시각화\"\"\"\n",
    "    masked_cam = cam_data * brain_mask\n",
    "    temp = masked_cam.copy()\n",
    "    clusters = []\n",
    "\n",
    "    for _ in range(top_n):\n",
    "        max_pos = np.unravel_index(temp.argmax(), temp.shape)\n",
    "        max_val = float(temp[max_pos])\n",
    "        if max_val < 0.01:\n",
    "            break\n",
    "        clusters.append({\"pos\": max_pos, \"val\": max_val})\n",
    "        d, h, w = max_pos\n",
    "        r = suppression_radius\n",
    "        d_lo = max(0, d - r); d_hi = min(temp.shape[0], d + r + 1)\n",
    "        h_lo = max(0, h - r); h_hi = min(temp.shape[1], h + r + 1)\n",
    "        w_lo = max(0, w - r); w_hi = min(temp.shape[2], w + r + 1)\n",
    "        temp[d_lo:d_hi, h_lo:h_hi, w_lo:w_hi] = 0\n",
    "\n",
    "    if not clusters:\n",
    "        print(f\"    [{cam_name}] 뇌 내부 유효 클러스터 없음\")\n",
    "        return\n",
    "\n",
    "    n = len(clusters)\n",
    "    print(f\"    [{cam_name}] 뇌 내부 Top-{n} 클러스터:\")\n",
    "    for i, cl in enumerate(clusters):\n",
    "        p = cl[\"pos\"]\n",
    "        print(f\"      #{i+1}  D={p[0]}, H={p[1]}, W={p[2]}  activation={cl['val']:.4f}\")\n",
    "\n",
    "    fig, axes = plt.subplots(n, 3, figsize=(12, 3.2 * n))\n",
    "    if n == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    thresh = percentile_in_mask(cam_data, brain_mask, 95, fallback=0.5)\n",
    "\n",
    "    for i, cl in enumerate(clusters):\n",
    "        pos = cl[\"pos\"]\n",
    "        val = cl[\"val\"]\n",
    "\n",
    "        view_configs = [\n",
    "            (\"Axial\",    pos[0], 0),\n",
    "            (\"Coronal\",  pos[1], 1),\n",
    "            (\"Sagittal\", pos[2], 2),\n",
    "        ]\n",
    "\n",
    "        for j, (view_name, sl_idx, dim) in enumerate(view_configs):\n",
    "            base, bm_2d = _get_slice(vol_np, brain_mask, dim, sl_idx)\n",
    "            if dim == 0:\n",
    "                heat = cam_data[sl_idx, :, :]\n",
    "            elif dim == 1:\n",
    "                heat = cam_data[:, sl_idx, :]\n",
    "            else:\n",
    "                heat = cam_data[:, :, sl_idx]\n",
    "\n",
    "            axes[i, j].imshow(base, cmap='gray')\n",
    "            heat_masked = _mask_heat(heat, thresh, bm_2d)\n",
    "            im = axes[i, j].imshow(heat_masked, cmap='turbo', alpha=0.55, vmin=thresh, vmax=1)\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(view_name, fontsize=11, fontweight='bold')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(\n",
    "                    f\"Cluster #{i+1}\\nD={pos[0]}, H={pos[1]}, W={pos[2]}\\nval={val:.3f}\",\n",
    "                    fontsize=9,\n",
    "                )\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='Activation')\n",
    "    fig.suptitle(\n",
    "        f\"[{stage_name}] {subject_id} | {cam_name} — Top-{n} Internal Clusters (brain-masked)\",\n",
    "        y=0.99, fontsize=12,\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.35, right=0.9)\n",
    "    safe = re.sub(r\"[^a-z0-9]+\", \"_\",\n",
    "                  f\"{subject_id}_{stage_name}_{cam_name}_clusters\".lower()).strip(\"_\")\n",
    "    plt.savefig(output_dir / f\"{safe}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# run_cam_for_sample\n",
    "# ============================================================\n",
    "\n",
    "def run_cam_for_sample(model, vol_input, vol_np, class_names, probs, pred,\n",
    "                       target_class, stage_name, subject_id, output_dir,\n",
    "                       prefer_attn: bool = False):\n",
    "    \"\"\"단일 샘플에 대해 Grad-CAM + Top-N 클러스터 시각화\"\"\"\n",
    "\n",
    "    brain_mask = create_brain_mask(vol_np, threshold=0.05)\n",
    "\n",
    "    with torch.enable_grad():\n",
    "        target_layer = _resolve_target_layer(model, prefer_attn=prefer_attn)\n",
    "        cam_gen = GradCAM3D(model, target_layer)\n",
    "        try:\n",
    "            cam = cam_gen(vol_input, class_idx=target_class)\n",
    "        finally:\n",
    "            cam_gen.remove()\n",
    "        cam_up = F.interpolate(cam, size=TARGET_SHAPE, mode='trilinear', align_corners=False)\n",
    "        gradcam_np = cam_up.detach().cpu().numpy()[0, 0]\n",
    "\n",
    "    if CAM_ONLY_HIPPOCAMPUS:\n",
    "        hippo_mask = create_roi_mask(TARGET_SHAPE, ROI_DEFINITIONS, CAM_ROI_KEYS, threshold=0.5)\n",
    "        gradcam_np = gradcam_np * hippo_mask\n",
    "\n",
    "    roi_defs_for_cam = (\n",
    "        {k: ROI_DEFINITIONS[k] for k in CAM_ROI_KEYS}\n",
    "        if CAM_ONLY_HIPPOCAMPUS else ROI_DEFINITIONS\n",
    "    )\n",
    "    masked_gradcam = gradcam_np * brain_mask\n",
    "    roi_scores = sorted(\n",
    "        compute_roi_abnormality(masked_gradcam, roi_defs_for_cam),\n",
    "        key=lambda x: x[\"score\"], reverse=True\n",
    "    )\n",
    "\n",
    "    print(f\"\\n  [{stage_name}] ROI 이상 부위 Top-5 (brain-masked Grad-CAM):\")\n",
    "    for rank, item in enumerate(roi_scores[:5], start=1):\n",
    "        desc = f\" - {item['description']}\" if item['description'] else \"\"\n",
    "        print(f\"    {rank}. {item['name']}{desc}: {item['score']*100:.2f}%\")\n",
    "\n",
    "    max_pos = np.unravel_index(masked_gradcam.argmax(), masked_gradcam.shape)\n",
    "\n",
    "    view_configs = [\n",
    "        (\"Axial\",    max_pos[0], 0),\n",
    "        (\"Coronal\",  max_pos[1], 1),\n",
    "        (\"Sagittal\", max_pos[2], 2),\n",
    "    ]\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(10, 12))\n",
    "    thresh = percentile_in_mask(gradcam_np, brain_mask, 95, fallback=0.5)\n",
    "\n",
    "    for row_idx, (view_name, slice_idx, dim) in enumerate(view_configs):\n",
    "        base, bm_2d = _get_slice(vol_np, brain_mask, dim, slice_idx)\n",
    "        if dim == 0:\n",
    "            heat = gradcam_np[slice_idx, :, :]\n",
    "        elif dim == 1:\n",
    "            heat = gradcam_np[:, slice_idx, :]\n",
    "        else:\n",
    "            heat = gradcam_np[:, :, slice_idx]\n",
    "\n",
    "        axes[row_idx, 0].imshow(base, cmap='gray')\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx, 0].set_title(\"Original\", fontsize=12, fontweight='bold')\n",
    "        axes[row_idx, 0].set_ylabel(f\"{view_name}\\n(slice={slice_idx})\", fontsize=11)\n",
    "        axes[row_idx, 0].set_xticks([])\n",
    "        axes[row_idx, 0].set_yticks([])\n",
    "\n",
    "        axes[row_idx, 1].imshow(base, cmap='gray')\n",
    "        heat_masked = _mask_heat(heat, thresh, bm_2d)\n",
    "        im = axes[row_idx, 1].imshow(heat_masked, cmap='turbo', alpha=0.55, vmin=thresh, vmax=1.0)\n",
    "        if row_idx == 0:\n",
    "            axes[row_idx, 1].set_title(\"Grad-CAM\", fontsize=12, fontweight='bold')\n",
    "        axes[row_idx, 1].set_xticks([])\n",
    "        axes[row_idx, 1].set_yticks([])\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.9, 0.15, 0.02, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='Activation')\n",
    "\n",
    "    prob_str = \" | \".join(f\"{n}: {probs[0, i].cpu().item()*100:.1f}%\" for i, n in enumerate(class_names))\n",
    "    fig.suptitle(\n",
    "        f\"[{stage_name}] Subject: {subject_id} | True: MCI | Pred: {class_names[pred]}\\n\"\n",
    "        f\"[{prob_str}] | Grad-CAM Max (D={max_pos[0]}, H={max_pos[1]}, W={max_pos[2]})\",\n",
    "        y=0.98, fontsize=11\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=0.02, hspace=0.08, right=0.88)\n",
    "    safe = re.sub(r\"[^a-z0-9]+\", \"_\", f\"{subject_id}_{stage_name}_grad_cam\".lower()).strip(\"_\")\n",
    "    plt.savefig(output_dir / f\"{safe}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    visualize_top_clusters(\n",
    "        vol_np, gradcam_np, \"Grad-CAM\", brain_mask,\n",
    "        stage_name, subject_id, output_dir, top_n=3, suppression_radius=10,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"CAM 유틸리티 정의 완료 (Grad-CAM only)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ROI 기반 CAM 이상 부위 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_roi_cam(vol_np, cam_data, cam_name, roi_scores, roi_definitions,\n",
    "                      stage_name, subject_id, output_dir, top_k=5,\n",
    "                      brain_mask=None, percentile: float = 95):\n",
    "    \"\"\"ROI 이상 점수 상위 K개 영역의 center 좌표에서 Grad-CAM 오버레이 시각화\"\"\"\n",
    "    top_rois = roi_scores[:top_k]\n",
    "    n = len(top_rois)\n",
    "    if n == 0:\n",
    "        print(\"    ROI 점수 데이터 없음\")\n",
    "        return\n",
    "\n",
    "    fig, axes = plt.subplots(n, 3, figsize=(12, 3.2 * n))\n",
    "    if n == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    thresh = percentile_in_mask(cam_data, brain_mask, percentile, fallback=0.5)\n",
    "\n",
    "    for i, roi_item in enumerate(top_rois):\n",
    "        roi_name = roi_item[\"name\"]\n",
    "        roi_def = roi_definitions[roi_name]\n",
    "        center = roi_def[\"center\"]\n",
    "        desc = roi_def.get(\"description\", roi_name)\n",
    "\n",
    "        view_configs = [\n",
    "            (\"Axial\",    int(center[0]), 0),\n",
    "            (\"Coronal\",  int(center[1]), 1),\n",
    "            (\"Sagittal\", int(center[2]), 2),\n",
    "        ]\n",
    "\n",
    "        for j, (view_name, sl_idx, dim) in enumerate(view_configs):\n",
    "            sl_idx = max(0, min(sl_idx, cam_data.shape[dim] - 1))\n",
    "\n",
    "            base, bm_2d = _get_slice(vol_np, brain_mask, dim, sl_idx)\n",
    "            if dim == 0:\n",
    "                heat = cam_data[sl_idx, :, :]\n",
    "            elif dim == 1:\n",
    "                heat = cam_data[:, sl_idx, :]\n",
    "            else:\n",
    "                heat = cam_data[:, :, sl_idx]\n",
    "\n",
    "            axes[i, j].imshow(base, cmap='gray')\n",
    "            heat_masked = _mask_heat(heat, thresh, bm_2d)\n",
    "            im = axes[i, j].imshow(heat_masked, cmap='turbo', alpha=0.55, vmin=thresh, vmax=1)\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(view_name, fontsize=11, fontweight='bold')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(\n",
    "                    f\"#{i+1} {roi_name}\\n{desc}\\nscore={roi_item['score']*100:.1f}%\",\n",
    "                    fontsize=8,\n",
    "                )\n",
    "\n",
    "    cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='Activation')\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"[{stage_name}] {subject_id} | {cam_name} — ROI Top-{n} Center Slices\",\n",
    "        y=0.99, fontsize=12,\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.35, right=0.9)\n",
    "    safe = re.sub(r\"[^a-z0-9]+\", \"_\",\n",
    "                  f\"{subject_id}_{stage_name}_{cam_name}_roi_slices\".lower()).strip(\"_\")\n",
    "    plt.savefig(output_dir / f\"{safe}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"visualize_roi_cam 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"ROI 기반 CAM 시각화 시작 (MCI 정답 상위 {min(MAX_CAM_SAMPLES, len(cam_targets))}개)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for rank, (_, row) in enumerate(cam_targets.iterrows(), start=1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"[{rank}/{len(cam_targets)}] Subject: {row['subject_id']}\")\n",
    "\n",
    "    vol = load_nifti(row[\"path\"])\n",
    "    vol_dev = vol.to(DEVICE)\n",
    "    vol_np = vol[0, 0].numpy()\n",
    "    brain_mask = create_brain_mask(vol_np, threshold=0.05)\n",
    "\n",
    "    for model, model_name, class_names, target_cls, stage_name in [\n",
    "        (cn_model, \"Stage1\", CN_CLASS_NAMES, 1, \"Stage1_CN-vs-CI\"),\n",
    "        (ci_model, \"Stage2\", CI_CLASS_NAMES, 0, \"Stage2_MCI-vs-AD\"),\n",
    "    ]:\n",
    "        with torch.enable_grad():\n",
    "            target_layer = _resolve_target_layer(model)\n",
    "            cam_gen = GradCAM3D(model, target_layer)\n",
    "            try:\n",
    "                cam_raw = cam_gen(vol_dev, class_idx=target_cls)\n",
    "            finally:\n",
    "                cam_gen.remove()\n",
    "            cam_up = F.interpolate(cam_raw, size=TARGET_SHAPE, mode='trilinear', align_corners=False)\n",
    "            gradcam_np = cam_up.detach().cpu().numpy()[0, 0]\n",
    "\n",
    "        # 뇌 마스크 적용한 Grad-CAM으로 ROI 점수 계산\n",
    "        masked_gradcam = gradcam_np * brain_mask\n",
    "        roi_scores = sorted(\n",
    "            compute_roi_abnormality(masked_gradcam, ROI_DEFINITIONS),\n",
    "            key=lambda x: x[\"score\"], reverse=True\n",
    "        )\n",
    "\n",
    "        print(f\"\\n  >> [{stage_name}] ROI 이상 점수 Top-5 (brain-masked Grad-CAM):\")\n",
    "        for r, item in enumerate(roi_scores[:5], start=1):\n",
    "            desc = f\" - {item['description']}\" if item['description'] else \"\"\n",
    "            print(f\"    {r}. {item['name']}{desc}: {item['score']*100:.2f}%\")\n",
    "\n",
    "        print(f\"\\n    >> Grad-CAM — ROI Top-5 Center Slices:\")\n",
    "        visualize_roi_cam(\n",
    "            vol_np, gradcam_np, \"Grad-CAM\", roi_scores, ROI_DEFINITIONS,\n",
    "            stage_name, row[\"subject_id\"], OUTPUT_DIR, top_k=5,\n",
    "            brain_mask=brain_mask,\n",
    "        )\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"ROI 기반 CAM 시각화 완료. 결과 저장: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## SHAP 분석 — ROI별 기여도 막대 그래프 + SHAP CAM 오버레이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import shap\n",
    "    HAS_SHAP = True\n",
    "    print(f\"SHAP 버전: {shap.__version__}\")\n",
    "except ImportError:\n",
    "    HAS_SHAP = False\n",
    "    print(\"SHAP 미설치. 다음 명령으로 설치 후 재실행:\\n  pip install shap\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SHAP 계산\n",
    "# ============================================================\n",
    "\n",
    "def compute_shap_values(model, vol_input, background_batch, class_idx: int = 0):\n",
    "    \"\"\"\n",
    "    shap.GradientExplainer로 복셀별 SHAP 값을 계산합니다.\n",
    "    Returns: np.ndarray shape (D, H, W)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    explainer = shap.GradientExplainer(model, background_batch)\n",
    "    shap_vals = explainer.shap_values(vol_input)\n",
    "\n",
    "    # shap 버전별 출력 형식 처리\n",
    "    if isinstance(shap_vals, list):\n",
    "        # list[class] 형식: 각 원소 shape (batch, C, D, H, W)\n",
    "        sv = np.array(shap_vals[class_idx])\n",
    "    else:\n",
    "        sv = np.array(shap_vals)\n",
    "        if sv.ndim == 6:   # (batch, n_classes, C, D, H, W)\n",
    "            sv = sv[:, class_idx]\n",
    "\n",
    "    # (1, 1, D, H, W) → (D, H, W)\n",
    "    while sv.ndim > 3:\n",
    "        sv = sv[0]\n",
    "\n",
    "    return sv.astype(np.float32)\n",
    "\n",
    "\n",
    "def compute_roi_shap_scores(shap_np, roi_definitions):\n",
    "    \"\"\"\n",
    "    ROI Gaussian 마스크로 SHAP 값을 가중 집계합니다.\n",
    "    - raw_shap : 부호 있는 가중 평균 (예측 클래스 방향 정보)\n",
    "    - score    : 절댓값 가중 평균 (중요도 순위용)\n",
    "    \"\"\"\n",
    "    D, H, W = shap_np.shape\n",
    "    dd, hh, ww = np.meshgrid(\n",
    "        np.arange(D, dtype=np.float32),\n",
    "        np.arange(H, dtype=np.float32),\n",
    "        np.arange(W, dtype=np.float32),\n",
    "        indexing='ij',\n",
    "    )\n",
    "    results = []\n",
    "    for name, roi in roi_definitions.items():\n",
    "        c = roi[\"center\"]\n",
    "        s = float(roi[\"sigma\"])\n",
    "        mask = np.exp(-((dd - c[0])**2 + (hh - c[1])**2 + (ww - c[2])**2) / (2 * s**2))\n",
    "        w_sum = float(mask.sum()) + 1e-8\n",
    "        raw_shap = float((shap_np * mask).sum() / w_sum)\n",
    "        abs_mean = float((np.abs(shap_np) * mask).sum() / w_sum)\n",
    "        results.append({\n",
    "            \"name\":        name,\n",
    "            \"description\": roi.get(\"description\", \"\"),\n",
    "            \"raw_shap\":    raw_shap,   # 부호 있음\n",
    "            \"score\":       abs_mean,   # 절댓값 (정렬용)\n",
    "        })\n",
    "    return sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# ROI별 SHAP 막대 그래프\n",
    "# ============================================================\n",
    "\n",
    "def visualize_roi_shap_bar(roi_shap_scores, stage_name, subject_id, output_dir, top_k=10):\n",
    "    \"\"\"ROI별 SHAP 기여도 수평 막대 그래프 (부호 있는 raw_shap 사용).\"\"\"\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    top    = roi_shap_scores[:top_k]\n",
    "    n      = len(top)\n",
    "    labels = [f\"{item['name']}\\n({item['description']})\" for item in reversed(top)]\n",
    "    values = [item['raw_shap'] for item in reversed(top)]\n",
    "    colors = ['#d73027' if v > 0 else '#4575b4' for v in values]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, max(4, n * 0.7)))\n",
    "    bars = ax.barh(range(n), values, color=colors, alpha=0.85,\n",
    "                   edgecolor='gray', linewidth=0.4)\n",
    "    ax.set_yticks(range(n))\n",
    "    ax.set_yticklabels(labels, fontsize=8)\n",
    "    ax.set_xlabel('Weighted Mean SHAP Value (ROI Gaussian mask)', fontsize=10)\n",
    "    ax.set_title(\n",
    "        f\"[{stage_name}] {subject_id}\\nROI-level SHAP Contributions (Top-{n})\",\n",
    "        fontsize=12, fontweight='bold', pad=10,\n",
    "    )\n",
    "    ax.axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "\n",
    "    x_max = max(abs(v) for v in values) if values else 1.0\n",
    "    for bar, val in zip(bars, values):\n",
    "        x      = bar.get_width()\n",
    "        offset = x_max * 0.02\n",
    "        ax.text(\n",
    "            x + (offset if x >= 0 else -offset),\n",
    "            bar.get_y() + bar.get_height() / 2,\n",
    "            f'{val:+.5f}',\n",
    "            va='center', ha='left' if x >= 0 else 'right', fontsize=7,\n",
    "        )\n",
    "\n",
    "    ax.legend(\n",
    "        handles=[\n",
    "            Patch(facecolor='#d73027', alpha=0.85, label='양(+): 예측 클래스 방향'),\n",
    "            Patch(facecolor='#4575b4', alpha=0.85, label='음(−): 반대 클래스 방향'),\n",
    "        ],\n",
    "        loc='lower right', fontsize=9,\n",
    "    )\n",
    "    plt.tight_layout()\n",
    "    safe = re.sub(r\"[^a-z0-9]+\", \"_\",\n",
    "                  f\"{subject_id}_{stage_name}_shap_bar\".lower()).strip(\"_\")\n",
    "    plt.savefig(output_dir / f\"{safe}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"    저장: {output_dir / (safe + '.png')}\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SHAP CAM 오버레이\n",
    "# ============================================================\n",
    "\n",
    "def visualize_roi_shap_cam(vol_np, shap_np, roi_shap_scores, roi_definitions,\n",
    "                           stage_name, subject_id, output_dir, top_k=5,\n",
    "                           brain_mask=None):\n",
    "    \"\"\"ROI 중심 좌표에서 |SHAP| 정규화 오버레이 시각화.\"\"\"\n",
    "    top_rois = roi_shap_scores[:top_k]\n",
    "    n        = len(top_rois)\n",
    "    if n == 0:\n",
    "        return\n",
    "\n",
    "    shap_abs  = np.abs(shap_np)\n",
    "    smin, smax = shap_abs.min(), shap_abs.max()\n",
    "    shap_norm  = (shap_abs - smin) / (smax - smin + 1e-8)\n",
    "    thresh     = percentile_in_mask(shap_norm, brain_mask, 95, fallback=0.3)\n",
    "\n",
    "    fig, axes = plt.subplots(n, 3, figsize=(12, 3.2 * n))\n",
    "    if n == 1:\n",
    "        axes = axes[np.newaxis, :]\n",
    "\n",
    "    im = None\n",
    "    for i, roi_item in enumerate(top_rois):\n",
    "        roi_name = roi_item[\"name\"]\n",
    "        roi_def  = roi_definitions[roi_name]\n",
    "        center   = roi_def[\"center\"]\n",
    "        desc     = roi_def.get(\"description\", roi_name)\n",
    "\n",
    "        view_configs = [\n",
    "            (\"Axial\",    int(center[0]), 0),\n",
    "            (\"Coronal\",  int(center[1]), 1),\n",
    "            (\"Sagittal\", int(center[2]), 2),\n",
    "        ]\n",
    "\n",
    "        for j, (view_name, sl_idx, dim) in enumerate(view_configs):\n",
    "            sl_idx = max(0, min(sl_idx, shap_norm.shape[dim] - 1))\n",
    "            base, bm_2d = _get_slice(vol_np, brain_mask, dim, sl_idx)\n",
    "\n",
    "            if   dim == 0: heat = shap_norm[sl_idx, :, :]\n",
    "            elif dim == 1: heat = shap_norm[:, sl_idx, :]\n",
    "            else:          heat = shap_norm[:, :, sl_idx]\n",
    "\n",
    "            axes[i, j].imshow(base, cmap='gray')\n",
    "            heat_masked = _mask_heat(heat, thresh, bm_2d)\n",
    "            im = axes[i, j].imshow(heat_masked, cmap='hot', alpha=0.55,\n",
    "                                   vmin=thresh, vmax=1)\n",
    "            axes[i, j].set_xticks([])\n",
    "            axes[i, j].set_yticks([])\n",
    "\n",
    "            if i == 0:\n",
    "                axes[i, j].set_title(view_name, fontsize=11, fontweight='bold')\n",
    "            if j == 0:\n",
    "                axes[i, j].set_ylabel(\n",
    "                    f\"#{i+1} {roi_name}\\n{desc}\\nSHAP={roi_item['raw_shap']:+.5f}\",\n",
    "                    fontsize=8,\n",
    "                )\n",
    "\n",
    "    if im is not None:\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.015, 0.7])\n",
    "        fig.colorbar(im, cax=cbar_ax, label='|SHAP| (normalized)')\n",
    "\n",
    "    fig.suptitle(\n",
    "        f\"[{stage_name}] {subject_id} | SHAP CAM — ROI Top-{n} Center Slices\",\n",
    "        y=0.99, fontsize=12,\n",
    "    )\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0.35, right=0.9)\n",
    "    safe = re.sub(r\"[^a-z0-9]+\", \"_\",\n",
    "                  f\"{subject_id}_{stage_name}_shap_cam_roi\".lower()).strip(\"_\")\n",
    "    plt.savefig(output_dir / f\"{safe}.png\", dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"    저장: {output_dir / (safe + '.png')}\")\n",
    "\n",
    "\n",
    "print(\"SHAP 유틸리티 정의 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# SHAP Background 배치 준비\n",
    "# ============================================================\n",
    "N_BACKGROUND = 8   # MPS/CPU: 5~10 권장 (GPU: 20~50)\n",
    "\n",
    "if HAS_SHAP:\n",
    "    print(f\"Background 샘플 {N_BACKGROUND}개 로드 중...\")\n",
    "    bg_paths = df_all.sample(min(N_BACKGROUND, len(df_all)), random_state=42)[\"path\"].tolist()\n",
    "    bg_tensors = []\n",
    "    for p in bg_paths:\n",
    "        try:\n",
    "            bg_tensors.append(load_nifti(p).to(DEVICE))\n",
    "        except Exception as e:\n",
    "            print(f\"  SKIP {p}: {e}\")\n",
    "\n",
    "    if not bg_tensors:\n",
    "        raise RuntimeError(\"Background 샘플 로드 실패\")\n",
    "\n",
    "    background_batch = torch.cat(bg_tensors, dim=0)   # (N, 1, D, H, W)\n",
    "    print(f\"Background batch 준비 완료: {background_batch.shape}  device={background_batch.device}\")\n",
    "else:\n",
    "    print(\"SHAP 미설치 — Background 배치 건너뜀\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ROI별 SHAP 시각화 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not HAS_SHAP:\n",
    "    print(\"SHAP 미설치: pip install shap\")\n",
    "else:\n",
    "    print(f\"ROI별 SHAP 시각화 시작 (MCI 정답 상위 {min(MAX_CAM_SAMPLES, len(cam_targets))}개)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for rank, (_, row) in enumerate(cam_targets.iterrows(), start=1):\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"[{rank}/{len(cam_targets)}] Subject: {row['subject_id']}\")\n",
    "\n",
    "        vol    = load_nifti(row[\"path\"])\n",
    "        vol_dev = vol.to(DEVICE)\n",
    "        vol_np  = vol[0, 0].numpy()\n",
    "        brain_mask = create_brain_mask(vol_np, threshold=0.05)\n",
    "\n",
    "        for model, class_names, target_cls, stage_name in [\n",
    "            (cn_model, CN_CLASS_NAMES, 1, \"Stage1_CN-vs-CI\"),\n",
    "            (ci_model, CI_CLASS_NAMES, 0, \"Stage2_MCI-vs-AD\"),\n",
    "        ]:\n",
    "            print(f\"\\n  [{stage_name}] SHAP 계산 중 (background={N_BACKGROUND})...\")\n",
    "            try:\n",
    "                shap_np = compute_shap_values(\n",
    "                    model, vol_dev, background_batch, class_idx=target_cls\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"    SHAP 계산 실패: {e}\")\n",
    "                continue\n",
    "\n",
    "            roi_shap_scores = compute_roi_shap_scores(shap_np, ROI_DEFINITIONS)\n",
    "\n",
    "            print(f\"  >> [{stage_name}] ROI SHAP 기여도 Top-5:\")\n",
    "            for r, item in enumerate(roi_shap_scores[:5], start=1):\n",
    "                desc = f\" - {item['description']}\" if item['description'] else \"\"\n",
    "                print(f\"    {r}. {item['name']}{desc}  SHAP={item['raw_shap']:+.5f}\")\n",
    "\n",
    "            print(f\"\\n    >> {stage_name} — ROI SHAP 막대 그래프:\")\n",
    "            visualize_roi_shap_bar(\n",
    "                roi_shap_scores, stage_name, row[\"subject_id\"], OUTPUT_DIR, top_k=10\n",
    "            )\n",
    "\n",
    "            print(f\"\\n    >> {stage_name} — SHAP CAM 오버레이 (ROI Top-5):\")\n",
    "            visualize_roi_shap_cam(\n",
    "                vol_np, shap_np, roi_shap_scores, ROI_DEFINITIONS,\n",
    "                stage_name, row[\"subject_id\"], OUTPUT_DIR, top_k=5,\n",
    "                brain_mask=brain_mask,\n",
    "            )\n",
    "\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ROI별 SHAP 시각화 완료. 결과 저장: {OUTPUT_DIR}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
